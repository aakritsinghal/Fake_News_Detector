{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aakrit's_Fake_News_Detector.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZtLQDPRFduFeaZuU6m38d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMnzXmNPTx5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Import Data { display-mode: \"form\" }\n",
        "import math\n",
        "import os\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "import pickle\n",
        "\n",
        "import requests, io, zipfile\n",
        "# Download class resources...\n",
        "r = requests.get(\"https://www.dropbox.com/s/2pj07qip0ei09xt/inspirit_fake_news_resources.zip?dl=1\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "basepath = '.'\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "with open(os.path.join(basepath, 'train_val_data.pkl'), 'rb') as f:\n",
        "  train_data, val_data = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AOq68_EWCmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_description_from_html(html):\n",
        "  soup = bs(html)\n",
        "  description_tag = soup.find('meta', attrs={'name':'og:description'}) or soup.find('meta', attrs={'property':'description'}) or soup.find('meta', attrs={'name':'description'})\n",
        "  if description_tag:\n",
        "    description = description_tag.get('content') or ''\n",
        "  else: # If there is no description, return empty string.\n",
        "    description = ''\n",
        "  return description\n",
        "\n",
        "def scrape_description(url):\n",
        "  if not url.startswith('http'):\n",
        "    url = 'http://' + url\n",
        "  response = requests.get(url, timeout=10)\n",
        "  html = response.text\n",
        "  description = get_description_from_html(html)\n",
        "  return description"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3vuLhfsUBa7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf44be06-cb52-44a0-9beb-54164d9914c4"
      },
      "source": [
        "def get_descriptions_from_data(data):\n",
        "  # A dictionary mapping from url to description for the websites in \n",
        "  # train_data.\n",
        "  descriptions = []\n",
        "  for site in tqdm(data):\n",
        "    url, html, label = site\n",
        "    descriptions.append(get_description_from_html(html)) \n",
        "  return descriptions\n",
        "  \n",
        "\n",
        "train_descriptions = get_descriptions_from_data(train_data)\n",
        "train_urls = [url for (url, html, label) in train_data]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2002/2002 [02:23<00:00, 13.94it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qpXplYDWFks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bc046f3-ee41-4859-cbbd-d01b9ccfeb0f"
      },
      "source": [
        "val_descriptions = get_descriptions_from_data(val_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 309/309 [00:21<00:00, 14.41it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyJ35geCV72O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2a2c0785-a1bb-4205-8bb0-4d0744a94469"
      },
      "source": [
        "vectorizer = CountVectorizer(max_features=300)\n",
        "\n",
        "vectorizer.fit(train_descriptions)\n",
        "\n",
        "def vectorize_data_descriptions(descriptions, vectorizer):\n",
        "  X = vectorizer.transform(descriptions).todense()\n",
        "  return X\n",
        "\n",
        "print('\\nPreparing train data...')\n",
        "bow_train_X = vectorize_data_descriptions(train_descriptions, vectorizer)\n",
        "bow_train_y = [label for url, html, label in train_data]\n",
        "\n",
        "print('\\nPreparing val data...')\n",
        "bow_val_X = vectorize_data_descriptions(val_descriptions, vectorizer)\n",
        "bow_val_y = [label for url, html, label in val_data]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing train data...\n",
            "\n",
            "Preparing val data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnsB_C0sWUeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e341fc39-669e-45c8-a198-80febf6b5363"
      },
      "source": [
        "model = LogisticRegression()\n",
        "\n",
        "model.fit(bow_train_X, bow_train_y)\n",
        "\n",
        "bow_train_y_pred = model.predict(bow_train_X)\n",
        "print('Train accuracy', accuracy_score(bow_train_y, bow_train_y_pred))\n",
        "\n",
        "bow_val_y_pred = model.predict(bow_val_X)\n",
        "print('Val accuracy', accuracy_score(bow_val_y, bow_val_y_pred))\n",
        "\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(bow_val_y, bow_val_y_pred))\n",
        "\n",
        "prf = precision_recall_fscore_support(bow_val_y, bow_val_y_pred)\n",
        "\n",
        "print('Precision:', prf[0][1])\n",
        "print('Recall:', prf[1][1])\n",
        "print('F-Score:', prf[2][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.8746253746253746\n",
            "Val accuracy 0.6634304207119741\n",
            "Confusion matrix:\n",
            "[[ 77  91]\n",
            " [ 13 128]]\n",
            "Precision: 0.5844748858447488\n",
            "Recall: 0.9078014184397163\n",
            "F-Score: 0.7111111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1AISGIJWYfQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d7e1838c-facc-47e9-86cb-533d93bdbb6c"
      },
      "source": [
        "VEC_SIZE = 300\n",
        "glove = GloVe(name='6B', dim=VEC_SIZE)\n",
        "\n",
        "# Returns word vector for word if it exists, else return None.\n",
        "def get_word_vector(word):\n",
        "    try:\n",
        "      return glove.vectors[glove.stoi[word.lower()]].numpy()\n",
        "    except KeyError:\n",
        "      return None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:27, 2.23MB/s]                           \n",
            "100%|█████████▉| 399743/400000 [00:45<00:00, 8757.99it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qGMox4pWbVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "04413101-4144-44e9-cf9e-cc4a1c36aa1c"
      },
      "source": [
        "#@title Word Similarity { run: \"auto\", display-mode: \"both\" }\n",
        "\n",
        "def cosine_similarity(vec1, vec2):    \n",
        "  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "word1 = \"good\" #@param {type:\"string\"}\n",
        "word2 = \"great\" #@param {type:\"string\"}\n",
        "\n",
        "print('Word 1:', word1)\n",
        "print('Word 2:', word2)\n",
        "\n",
        "def cosine_similarity_of_words(word1, word2):\n",
        "  vec1 = get_word_vector(word1)\n",
        "  vec2 = get_word_vector(word2)\n",
        "  \n",
        "  if vec1 is None:\n",
        "    print(word1, 'is not a valid word. Try another.')\n",
        "  if vec2 is None:\n",
        "    print(word2, 'is not a valid word. Try another.')\n",
        "  if vec1 is None or vec2 is None:\n",
        "    return None\n",
        "  \n",
        "  return cosine_similarity(vec1, vec2)\n",
        "  \n",
        "print('\\nCosine similarity:', cosine_similarity_of_words(word1, word2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 1: good\n",
            "Word 2: great\n",
            "\n",
            "Cosine similarity: 0.6410047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NG8ykrtW5oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def glove_transform_data_descriptions(descriptions):\n",
        "    X = np.zeros((len(descriptions), VEC_SIZE))\n",
        "    for i, description in enumerate(descriptions):\n",
        "        found_words = 0.0\n",
        "        description = description.strip()\n",
        "        for word in description.split(): \n",
        "            vec = get_word_vector(word)\n",
        "            if vec is not None:\n",
        "                found_words += 1\n",
        "                X[i] += vec\n",
        "        if found_words > 0:\n",
        "            X[i] /= found_words\n",
        "            \n",
        "    return X\n",
        "    \n",
        "glove_train_X = glove_transform_data_descriptions(train_descriptions)\n",
        "glove_train_y = [label for (url, html, label) in train_data]\n",
        "\n",
        "glove_val_X = glove_transform_data_descriptions(val_descriptions)\n",
        "glove_val_y = [label for (url, html, label) in val_data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8mVNYGJXJh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0de46765-7b80-44ba-a325-59d9a88b4c4b"
      },
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(glove_train_X, glove_train_y)\n",
        "\n",
        "glove_train_y_pred = model.predict(glove_train_X)\n",
        "print('Train accuracy', accuracy_score(glove_train_y, glove_train_y_pred))\n",
        "\n",
        "glove_val_y_pred = model.predict(glove_val_X)\n",
        "print('Val accuracy', accuracy_score(glove_val_y, glove_val_y_pred))\n",
        "\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(glove_val_y, glove_val_y_pred))\n",
        "\n",
        "prf = precision_recall_fscore_support(glove_val_y, glove_val_y_pred)\n",
        "\n",
        "print('Precision:', prf[0][1])\n",
        "print('Recall:', prf[1][1])\n",
        "print('F-Score:', prf[2][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.8656343656343657\n",
            "Val accuracy 0.7702265372168284\n",
            "Confusion matrix:\n",
            "[[116  52]\n",
            " [ 19 122]]\n",
            "Precision: 0.7011494252873564\n",
            "Recall: 0.8652482269503546\n",
            "F-Score: 0.7746031746031746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9igzATFXQAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(train_X, train_y, val_X, val_y):\n",
        "  model = LogisticRegression(solver='liblinear')\n",
        "  model.fit(train_X, train_y)\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def train_and_evaluate_model(train_X, train_y, val_X, val_y):\n",
        "  model = train_model(train_X, train_y, val_X, val_y)\n",
        "  \n",
        "  train_y_pred = model.predict(train_X)\n",
        "  print('Train accuracy', accuracy_score(train_y, train_y_pred))\n",
        "\n",
        "  val_y_pred = model.predict(val_X)\n",
        "  print('Val accuracy', accuracy_score(val_y, val_y_pred))\n",
        "\n",
        "  print('Confusion matrix:')\n",
        "  print(confusion_matrix(val_y, val_y_pred))\n",
        "\n",
        "  prf = precision_recall_fscore_support(val_y, val_y_pred)\n",
        "\n",
        "  print('Precision:', prf[0][1])\n",
        "  print('Recall:', prf[1][1])\n",
        "  print('F-Score:', prf[2][1])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFj8FoxZXV2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "8dd2e9ea-a4de-4460-9b49-7b43c9282824"
      },
      "source": [
        "def prepare_data(data, featurizer):\n",
        "    X = []\n",
        "    y = []\n",
        "    for datapoint in data:\n",
        "        url, html, label = datapoint\n",
        "        html = html.lower() \n",
        "        y.append(label)\n",
        "        features = featurizer(url, html)\n",
        "        feature_descriptions, feature_values = zip(*features.items())\n",
        "        X.append(feature_values)\n",
        "\n",
        "    return X, y, feature_descriptions\n",
        "\n",
        "def get_normalized_count(html, phrase):\n",
        "    return math.log(1 + html.count(phrase.lower()))\n",
        "\n",
        "def keyword_featurizer(url, html):\n",
        "    features = {}\n",
        "    \n",
        "\n",
        "    features['.com domain'] = url.endswith('.com')\n",
        "    features['.org domain'] = url.endswith('.org')\n",
        "    features['.net domain'] = url.endswith('.net')\n",
        "    features['.info domain'] = url.endswith('.info')\n",
        "    features['.org domain'] = url.endswith('.org')\n",
        "    features['.biz domain'] = url.endswith('.biz')\n",
        "    features['.ru domain'] = url.endswith('.ru')\n",
        "    features['.co.uk domain'] = url.endswith('.co.uk')\n",
        "    features['.co domain'] = url.endswith('.co')\n",
        "    features['.tv domain'] = url.endswith('.tv')\n",
        "    features['.news domain'] = url.endswith('.news')\n",
        "    \n",
        "    keywords = ['trump', 'biden', 'clinton', 'sports', 'finance']\n",
        "    \n",
        "    for keyword in keywords:\n",
        "      features[keyword + ' keyword'] = get_normalized_count(html, keyword)\n",
        "    \n",
        "    return features\n",
        "\n",
        "keyword_train_X, train_y, _ = prepare_data(train_data, keyword_featurizer)\n",
        "keyword_val_X, val_y, _ = prepare_data(val_data, keyword_featurizer)\n",
        "\n",
        "train_and_evaluate_model(keyword_train_X, train_y, keyword_val_X, val_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.7922077922077922\n",
            "Val accuracy 0.7346278317152104\n",
            "Confusion matrix:\n",
            "[[106  62]\n",
            " [ 20 121]]\n",
            "Precision: 0.6612021857923497\n",
            "Recall: 0.8581560283687943\n",
            "F-Score: 0.7469135802469136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYMZNxqRXrmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "d5957c7c-c7b2-4c27-885a-26af135d4bee"
      },
      "source": [
        "vectorizer = CountVectorizer(max_features=300)\n",
        "\n",
        "vectorizer.fit(train_descriptions)\n",
        "\n",
        "def vectorize_data_descriptions(data_descriptions, vectorizer):\n",
        "  X = vectorizer.transform(data_descriptions).todense()\n",
        "  return X\n",
        "\n",
        "bow_train_X = vectorize_data_descriptions(train_descriptions, vectorizer)\n",
        "bow_val_X = vectorize_data_descriptions(val_descriptions, vectorizer)\n",
        "\n",
        "train_and_evaluate_model(bow_train_X, train_y, bow_val_X, val_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.8746253746253746\n",
            "Val accuracy 0.6634304207119741\n",
            "Confusion matrix:\n",
            "[[ 77  91]\n",
            " [ 13 128]]\n",
            "Precision: 0.5844748858447488\n",
            "Recall: 0.9078014184397163\n",
            "F-Score: 0.7111111111111111\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rAzwvrBXylb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "9d7d3ea6-6ca3-43fb-b283-51152d5806d7"
      },
      "source": [
        "VEC_SIZE = 300\n",
        "glove = GloVe(name='6B', dim=VEC_SIZE)\n",
        "\n",
        "# Returns word vector for word if it exists, else return None.\n",
        "def get_word_vector(word):\n",
        "    try:\n",
        "      return glove.vectors[glove.stoi[word.lower()]].numpy()\n",
        "    except KeyError:\n",
        "      return None\n",
        "\n",
        "def glove_transform_data_descriptions(descriptions):\n",
        "    X = np.zeros((len(descriptions), VEC_SIZE))\n",
        "    for i, description in enumerate(descriptions):\n",
        "        found_words = 0.0\n",
        "        description = description.strip()\n",
        "        for word in description.split(): \n",
        "            vec = get_word_vector(word)\n",
        "            if vec is not None:\n",
        "                # Increment found_words and add vec to X[i].\n",
        "                found_words += 1\n",
        "                X[i] += vec\n",
        "                ### END CODE HERE ###\n",
        "        # We divide the sum by the number of words added, so we have the\n",
        "        # average word vector.\n",
        "        if found_words > 0:\n",
        "            X[i] /= found_words\n",
        "            \n",
        "    return X\n",
        "\n",
        "# Note that you can use train_y and val_y from before, since these are the\n",
        "# same for both the keyword approach and the BOW approach.\n",
        "\n",
        "glove_train_X = glove_transform_data_descriptions(train_descriptions)\n",
        "glove_val_X = glove_transform_data_descriptions(val_descriptions)\n",
        "\n",
        "train_and_evaluate_model(glove_train_X, train_y, glove_val_X, val_y)\n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.8656343656343657\n",
            "Val accuracy 0.7702265372168284\n",
            "Confusion matrix:\n",
            "[[116  52]\n",
            " [ 19 122]]\n",
            "Precision: 0.7011494252873564\n",
            "Recall: 0.8652482269503546\n",
            "F-Score: 0.7746031746031746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI--6oB3ZVS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5118594c-f717-4559-e300-852de094bdd3"
      },
      "source": [
        "def combine_features(X_list):\n",
        "  return np.concatenate(X_list, axis=1)\n",
        "\n",
        "# First, produce combined_train_X and combined_val_X using 2 calls to \n",
        "# combine_features, using keyword_train_X, bow_train_X, glove_train_X\n",
        "# and keyword_val_X, bow_val_X, glove_val_X from before.\n",
        "combined_train_X = combine_features([keyword_train_X, bow_train_X, glove_train_X])\n",
        "combined_val_X = combine_features([keyword_val_X, bow_val_X, glove_val_X])\n",
        "\n",
        "model = train_and_evaluate_model(combined_train_X, train_y, combined_val_X, val_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy 0.9175824175824175\n",
            "Val accuracy 0.7993527508090615\n",
            "Confusion matrix:\n",
            "[[119  49]\n",
            " [ 13 128]]\n",
            "Precision: 0.7231638418079096\n",
            "Recall: 0.9078014184397163\n",
            "F-Score: 0.8050314465408805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-r8dHa8at0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57617029-0700-463a-e232-e010f268a6d5"
      },
      "source": [
        "#@title Live Fake News Classification Demo { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "def get_data_pair(url):\n",
        "  if not url.startswith('http'):\n",
        "      url = 'http://' + url\n",
        "  url_pretty = url\n",
        "  if url_pretty.startswith('http://'):\n",
        "      url_pretty = url_pretty[7:]\n",
        "  if url_pretty.startswith('https://'):\n",
        "      url_pretty = url_pretty[8:]\n",
        "      \n",
        "  # Scrape website for HTML\n",
        "  response = requests.get(url, timeout=10)\n",
        "  htmltext = response.text\n",
        "  \n",
        "  return url_pretty, htmltext\n",
        "\n",
        "curr_url = \"www.youtube.com\" #@param {type:\"string\"}\n",
        "\n",
        "url, html = get_data_pair(curr_url)\n",
        "\n",
        "# Call on the output of *keyword_featurizer* or something similar\n",
        "# to transform it into a format that allows for concatenation. See\n",
        "# example below.\n",
        "def dict_to_features(features_dict):\n",
        "  X = np.array(list(features_dict.values())).astype('float')\n",
        "  X = X[np.newaxis, :]\n",
        "  return X\n",
        "def featurize_data_pair(url, html):\n",
        "  # Approach 1.\n",
        "  keyword_X = dict_to_features(keyword_featurizer(url, html))\n",
        "  # Approach 2.\n",
        "  description = get_description_from_html(html)\n",
        "  \n",
        "  bow_X = vectorize_data_descriptions([description], vectorizer)\n",
        "  \n",
        "  # Approach 3.\n",
        "  glove_X = glove_transform_data_descriptions([description])\n",
        "  \n",
        "  X = combine_features([keyword_X, bow_X, glove_X])\n",
        "  \n",
        "  return X\n",
        "\n",
        "curr_X = featurize_data_pair(url, html)\n",
        "\n",
        "model = train_model(combined_train_X, train_y, combined_val_X, val_y)\n",
        "\n",
        "curr_y = model.predict(curr_X)[0]\n",
        "  \n",
        "  \n",
        "if curr_y < .5:\n",
        "  print(curr_url, 'appears to be real.')\n",
        "else:\n",
        "  print(curr_url, 'appears to be fake.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "www.youtube.com appears to be real.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLdkWVaBax-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "4c3d693b-46a3-4d59-ff74-ebdbbbe71f98"
      },
      "source": [
        "### PUT TEST CODE HERE ###\n",
        "with open(os.path.join(basepath, 'test_data.pkl'), 'rb') as f:\n",
        "  test_data = pickle.load(f)\n",
        "  \n",
        "model = train_model(combined_train_X, train_y, combined_val_X, val_y)\n",
        "\n",
        "print('Loading test data...')\n",
        "test_X = []\n",
        "for url, html, label in test_data:\n",
        "  curr_X = np.array(featurize_data_pair(url, html))\n",
        "  test_X.append(curr_X[0])\n",
        "  \n",
        "test_X = np.array(test_X)\n",
        "\n",
        "test_y = [label for url, html, label in test_data]\n",
        "\n",
        "print('Done loading test data...')\n",
        "\n",
        "test_y_pred = model.predict(test_X)\n",
        "\n",
        "print('Test accuracy', accuracy_score(test_y, test_y_pred))\n",
        "\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(test_y, test_y_pred))\n",
        "\n",
        "prf = precision_recall_fscore_support(test_y, test_y_pred)\n",
        "\n",
        "print('Precision:', prf[0][1])\n",
        "print('Recall:', prf[1][1])\n",
        "print('F-Score:', prf[2][1])  \n",
        "### END CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading test data...\n",
            "Done loading test data...\n",
            "Test accuracy 0.8739837398373984\n",
            "Confusion matrix:\n",
            "[[104  30]\n",
            " [  1 111]]\n",
            "Precision: 0.7872340425531915\n",
            "Recall: 0.9910714285714286\n",
            "F-Score: 0.8774703557312252\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}